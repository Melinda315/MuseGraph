{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3826514a-31f4-4dc9-80db-56b566a8e693",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "b72dc204-796c-4836-8fcb-7fc627eb2ddf",
   "metadata": {
    "tags": []
   },
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "Index = []\n",
    "Title = {}\n",
    "Year = {}\n",
    "Abstract = {}\n",
    "train_Index = []\n",
    "valid_Index = []\n",
    "test_Index = []\n",
    "\n",
    "with open('./train_data.csv', 'r') as f:\n",
    "    reader = list(csv.reader(f))\n",
    "    for r in trange(len(reader)):\n",
    "        row = reader[r]\n",
    "        Index.append(int(row[0]))\n",
    "        train_Index.append(int(row[0]))\n",
    "        Title[int(row[0])] = (row[2])\n",
    "        Year[int(row[0])] = (row[3])\n",
    "        Abstract[int(row[0])] = (row[4])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "40542956-b405-4ecf-b926-c824edf9cd4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "with open('./valid_data.csv', 'r') as f:\n",
    "    reader = list(csv.reader(f))\n",
    "    for r in trange(len(reader)):\n",
    "        row = reader[r]\n",
    "        Index.append(int(row[0]))\n",
    "        valid_Index.append(int(row[0]))\n",
    "        Title[int(row[0])] = (row[2])\n",
    "        Year[int(row[0])] = (row[3])\n",
    "        Abstract[int(row[0])] = (row[4])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef2bd248-1bf1-4f06-a43f-bfe5f5719b2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "with open('./test_data.csv', 'r') as f:\n",
    "    reader = list(csv.reader(f))\n",
    "    for r in trange(len(reader)):\n",
    "        row = reader[r]\n",
    "        Index.append(int(row[0]))\n",
    "        test_Index.append(int(row[0]))\n",
    "        Title[int(row[0])] = (row[2])\n",
    "        Year[int(row[0])] = (row[3])\n",
    "        Abstract[int(row[0])] = (row[4])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f7ac96a8-ade8-4e79-a3ed-b515e2538f3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Label = {}\n",
    "with open('./labels.txt','r') as file:\n",
    "    for line in file:\n",
    "        temp1,temp2 = line[:-1].split('\\t')\n",
    "        Label[int(temp1)] = int(temp2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1544cc7c-b718-494b-8868-00f2ac990331",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate # of Node Tokens"
   ]
  },
  {
   "cell_type": "code",
   "id": "177513af-5dbd-46bf-927a-76e2257ca081",
   "metadata": {
    "tags": []
   },
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"Meta-Llama-3-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def calculate_token_num(text):\n",
    "    encoded = tokenizer.encode(text)\n",
    "    return len(encoded)\n",
    "\n",
    "node_token_num = []\n",
    "\n",
    "for i in trange(len(Title)):\n",
    "    text = Title[i] + Abstract[i]\n",
    "    node_token_num.append(calculate_token_num(text))\n",
    "print(len(node_token_num))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8abbcb78-41d6-4420-b1d0-4b9863fc2116",
   "metadata": {
    "tags": []
   },
   "source": [
    "import numpy as np\n",
    "tokens = np.array(node_token_num)\n",
    "print(f\"Max #node tokens: {tokens.max()}\")\n",
    "print(f\"Min #node tokens: {tokens.min()}\")\n",
    "print(f\"Avg. #node tokens: {tokens.mean()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7e5285a5-1719-48fa-abb8-85dec099cb72",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate # of Node Degrees"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "Graph=[[] for i in range(len(Title))]\n",
    "Self_to_Self_node_count = 0\n",
    "Edge_Num = 0\n",
    "with open('./graph.txt','r') as file:\n",
    "    for line in file:  \n",
    "        start,end,_=line[:-1].split('\\t')\n",
    "        Edge_Num+=2\n",
    "        if int(end) == int(start): Self_to_Self_node_count+=1\n",
    "        Graph[int(start)].append(int(end))\n",
    "        Graph[int(end)].append(int(start))\n",
    "    print(\"Self-Self:\", Self_to_Self_node_count)\n",
    "    print(\"# Nodes:\", len(Graph))\n",
    "    print(\"# Edges:\", Edge_Num)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11d4cec7fe4ebfce",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5a4d1c78-bb3c-49a7-b677-5197ee6238ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "node_degree_num = []\n",
    "count=0\n",
    "for i in trange(len(Graph)): \n",
    "    node_degree_num.append(len(Graph[i]))\n",
    "    \n",
    "    if len(Graph[i])==0: count+=1\n",
    "\n",
    "degrees_before = np.array(node_degree_num)\n",
    "\n",
    "print(f\"Max #node degrees_before: {degrees_before.max()}\")\n",
    "print(f\"Min #node degrees_before: {degrees_before.min()}\")\n",
    "print(f\"Avg. #node degrees_before: {degrees_before.mean()}\")\n",
    "\n",
    "print(f\"#node degree=0: {count}\")\n",
    "print(f\"#node degree=0/#total node: {count/len(Graph)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7a06fabd-cfe1-4235-9440-f047b38cc43a",
   "metadata": {
    "tags": []
   },
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "count_train=0\n",
    "count_valid=0\n",
    "count_test=0\n",
    "for i in train_Index: \n",
    "    if len(Graph[int(i)])==0: count_train += 1\n",
    "for i in valid_Index: \n",
    "    if len(Graph[int(i)])==0: count_valid += 1   \n",
    "for i in test_Index: \n",
    "    if len(Graph[int(i)])==0: count_test += 1\n",
    "\n",
    "print(f\"#node degree=0 on training: {count_train}\")\n",
    "print(f\"#node degree=0/#total node on training: {count_train/len(train_Index)}\")\n",
    "\n",
    "print(f\"#node degree=0 on validation: {count_valid}\")\n",
    "print(f\"#node degree=0/#total node on validation: {count_valid/len(valid_Index)}\")\n",
    "\n",
    "print(f\"#node degree=0 on testing: {count_test}\")\n",
    "print(f\"#node degree=0/#total node on testing: {count_test/len(test_Index)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a254849f-9b06-4fff-aea9-a49562ce3a31",
   "metadata": {
    "tags": []
   },
   "source": [
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "node_degree_num = []\n",
    "for i in trange(len(Graph)): node_degree_num.append(len(Graph[i]))\n",
    "\n",
    "degrees = np.array(node_degree_num)\n",
    "degrees = np.ceil(np.log1p(degrees))  \n",
    "\n",
    "print(f\"Max #node degrees: {degrees.max()}\")\n",
    "print(f\"Min #node degrees: {degrees.min()}\")\n",
    "print(f\"Avg. #node degrees: {degrees.mean()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4d8eff45-f91d-40cc-b320-cdda59e77dd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate Node H"
   ]
  },
  {
   "cell_type": "code",
   "id": "a6dca92f-19e3-42fb-bda9-7972f3ff73d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "H = tokens*degrees # H = T * [log(D+1)]\n",
    "print(\"# Nodes:\", len(H))\n",
    "print(f\"Max node H: {H.max()}\")\n",
    "print(f\"Min node H: {H.min()}\")\n",
    "print(f\"Avg. node H: {H.mean()}\")\n",
    "print(f\"Sum node H: {H.sum()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c096c382-f5c4-48e3-9d2b-d66658a3716d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate Node's one-hop Neighbors and Random Walks"
   ]
  },
  {
   "cell_type": "code",
   "id": "54252f5a-32b8-4ef8-8aef-c86e3d0dd7a1",
   "metadata": {
    "tags": []
   },
   "source": "train_nodes=train_Index",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "092b3ec4-093a-45d2-b7ce-4414fabbab84",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "Neighs = {}\n",
    "for node in train_nodes: Neighs[node] = []\n",
    "Avg_degree = degrees_before.mean()\n",
    "\n",
    "for i,central_node in enumerate(train_nodes):\n",
    "    \n",
    "    neighs = Graph[central_node] # Neighbors\n",
    "    central_node_H = H[central_node]/2 # H*/2\n",
    "    \n",
    "    neighs2H = {}\n",
    "    for j in neighs: neighs2H[j] = H[j]\n",
    "    sorted_neighs2H = dict(sorted(neighs2H.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    # Obtain central node's Neighbor (#Neighbors <= Avg. #Degree)\n",
    "    Neigh_temp = []\n",
    "    for neigh, neigh_H in sorted_neighs2H.items(): Neigh_temp.append(neigh)\n",
    "    if len(Neigh_temp) >= int(Avg_degree): \n",
    "        Neighs[central_node]= Neigh_temp[:int(Avg_degree)]\n",
    "        for neigh in range(int(Avg_degree),len(Neigh_temp)):\n",
    "             if sorted_neighs2H[Neigh_temp[neigh]] >= central_node_H: Neighs[central_node].append(Neigh_temp[neigh])\n",
    "    else:  Neighs[central_node] = Neigh_temp\n",
    "\n",
    "\n",
    "\n",
    "count =0\n",
    "avg_count=0\n",
    "for i,central_node in enumerate(train_nodes):\n",
    "    if len(Neighs[central_node])==0: count+=1\n",
    "    avg_count+=len(Neighs[central_node])\n",
    "print(f\"#Central Node's obtained Neighbor=0: {count}\")\n",
    "print(f\"#Central Node's obtained Neighbor=0: {count/len(train_nodes)*100}%\")\n",
    "print(f\"Avg. #Central Node's obtained Neighbor: {avg_count/len(train_nodes)}\")\n",
    "print(f\"Avg. #Central Node's obtained Neighbor (#/=0): {avg_count/(len(train_nodes)-count)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "860a4018-2d0f-4006-9f8a-35cc03ac3fa9",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "import random\n",
    "RWs = {}\n",
    "for node in train_nodes: RWs[node] = []\n",
    "start_idx = train_nodes \n",
    "\n",
    "rand=random.Random()\n",
    "max_walk_num = int(Avg_degree)\n",
    "alpha=0.15\n",
    "path_length=10000\n",
    "for line in tqdm(range(len(start_idx))):\n",
    "    central_node = start_idx[line]\n",
    "\n",
    "    if len(Graph[central_node])==0: continue\n",
    "\n",
    "    if len(Neighs[central_node]) < max_walk_num: \n",
    "        walk_num = max_walk_num - len(Neighs[central_node])\n",
    "    else: \n",
    "        continue\n",
    "\n",
    "    node_paths = []\n",
    "    while len(node_paths) < walk_num:\n",
    "        temp_path=[]\n",
    "        start = central_node\n",
    "        temp_path.append(start)\n",
    "        \n",
    "        if len(Graph[temp_path[-1]]) == 0: break \n",
    "        for i in range(path_length):\n",
    "            cur = temp_path[-1]\n",
    "\n",
    "            if (len(Graph[cur])>0) and rand.random()>=alpha:\n",
    "                next_ = rand.choice(Graph[cur])\n",
    "                while(rand.random()>=alpha): \n",
    "                    next_ = rand.choice(Graph[cur]) \n",
    "                temp_path.append(next_)\n",
    "            else: break\n",
    "        if len(temp_path)>=2 and len(temp_path)<=10: node_paths.append(temp_path)\n",
    "    RWs[central_node] = node_paths"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f897da2f-4b3a-492c-bca9-b834aa73ca18",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "count =0\n",
    "avg_count=0\n",
    "for i,central_node in enumerate(train_nodes):\n",
    "    if len(RWs[central_node])==0: count+=1\n",
    "    avg_count+=len(RWs[central_node])\n",
    "print(f\"#Central Node's obtained RWs=0: {count}\")\n",
    "print(f\"#Central Node's obtained RWs=0: {count/len(train_nodes)*100}%\")\n",
    "print(f\"Avg. #Central Node's obtained RWs: {avg_count/len(train_nodes)}\")\n",
    "print(f\"Avg. #Central Node's obtained RWs (#/=0): {avg_count/(len(train_nodes)-count)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "522c8152-6698-4aa8-8775-5571388fe81f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate Node Classification Instruction"
   ]
  },
  {
   "cell_type": "code",
   "id": "9b51ce1d-a271-4c39-a63d-dd1a9ab6fa1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "def get_subgraph(central_node, Neighs, RWs):\n",
    "    \n",
    "    Input =  \"The compact graph description of this PAPER is listed as follows:\\n\"\n",
    "    Input += \"Title: {\" + Title[central_node] + \"} Abstract: {\" + Abstract[central_node] + \"}\"\n",
    "    \n",
    "    if len(Neighs)==0 and len(RWs)==0: return Input\n",
    "    else: Input += \" \"\n",
    "    \n",
    "    #---------------------------------------------------------------------\n",
    "    # 构造ego graph nodes\n",
    "    input_graph = \"Ego graph nodes: {\"\n",
    "    graph_node = []\n",
    "    graph_node.append(central_node)\n",
    "    \n",
    "    # 加入neigh中node信息\n",
    "    temp_nodes = []\n",
    "    for node in Neighs: \n",
    "        if node == central_node: continue\n",
    "        temp_nodes.append(node)\n",
    "   \n",
    "    # 加入RW中node信息:\n",
    "    for path in RWs:\n",
    "        for node in path:\n",
    "            if node == central_node: continue\n",
    "            temp_nodes.append(node)\n",
    "           \n",
    "    temp_nodes = list(set(temp_nodes))\n",
    "    graph_node += temp_nodes\n",
    "    \n",
    "    count = 1\n",
    "    node2index = {}\n",
    "    input_graph += \"PAPER: [\"\n",
    "    for j,node in enumerate(graph_node):\n",
    "        if j != (len(graph_node)-1): input_graph += (\"(\"+str(j+1)+\") \\'\" +Title[node]+\"\\', \")\n",
    "        else: input_graph += (\"(\"+str(j+1)+\") \\'\" +Title[node]+\"\\']}\\n\")\n",
    "        node2index[node]=str(j+1)\n",
    "\n",
    "    Input += input_graph\n",
    "    \n",
    "    #---------------------------------------------------------------------\n",
    "    # 构造 Neighborhood information\n",
    "    input_neighborhood = \"One-hop neighbors: {\"\n",
    "    count = 0\n",
    "    for j,node in enumerate(Neighs):\n",
    "        if j!= len(Neighs)-1: input_neighborhood += (\"(\"+node2index[node] + \"), \")\n",
    "        else: input_neighborhood += (\"(\"+node2index[node] + \")}\\n\")\n",
    "    Input += input_neighborhood\n",
    "    \n",
    "    #---------------------------------------------------------------------\n",
    "    # 构造 RW\n",
    "    \n",
    "    if len(RWs)>0:\n",
    "        input_rw = \"Random walks: {\"\n",
    "        for j,path in enumerate(RWs):\n",
    "            input_rw += (chr(ord('A')+j) + \". \")\n",
    "            for k,node in enumerate(path):\n",
    "                if k != len(path)-1:\n",
    "                    temp = \"(\"+ node2index[node] + \") cited \"\n",
    "                    input_rw += temp\n",
    "                else: \n",
    "                    temp = \"(\"+ node2index[node] + \")\"\n",
    "                    input_rw += temp\n",
    "            if j!= len(RWs)-1: input_rw += \"; \"\n",
    "            else: input_rw += \"}\"\n",
    "        Input += input_rw\n",
    "    return Input"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0b5e2e03-e7ca-446e-8ab9-2bf05bc12c97",
   "metadata": {
    "tags": []
   },
   "source": [
    "NC_Type = []\n",
    "with open('./label_text.dat','r') as file:\n",
    "    for line in file:\n",
    "        temp1,temp2 = line[:-1].split('\\t')\n",
    "        NC_Type.append(temp2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aea2c01f-4023-4d20-a7a9-19454038fe23",
   "metadata": {
    "tags": []
   },
   "source": [
    "type_text = \"{\"\n",
    "for i,L in enumerate(NC_Type):\n",
    "    if i!= len(NC_Type)-1: type_text += str(i+1) + \". \" + L + \" \"\n",
    "    else: type_text += str(i+1) + \". \" + L + \"}\"\n",
    "type_text"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0521901a-08a1-485c-b67d-36972184663f",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "texts = []\n",
    "for i, central_node in enumerate(train_nodes): \n",
    "    text = {}\n",
    "    Instruction = \"Given the target PAPER with the compact graph description in Arxiv dataset, which of the following subcategories of computer science does this PAPER belong to: \" + type_text + \\\n",
    "    \". Directly give the most likely category of this PAPER.\" \n",
    "    Output = str(Label[central_node]+1) + \". \" + NC_Type[Label[central_node]]\n",
    "    Input = get_subgraph(central_node, Neighs[central_node], RWs[central_node])\n",
    "    \n",
    "    text[\"instruction\"] = Instruction\n",
    "    text[\"input\"] = Input\n",
    "    text[\"output\"] = Output\n",
    "    text[\"index\"] =  int(central_node)\n",
    "\n",
    "    texts.append(text) "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52617cde-809b-4bfb-83d9-cbe6e3b4b875",
   "metadata": {
    "tags": []
   },
   "source": [
    "import json\n",
    "with open(\"nc_arxiv.json\", \"w\") as f:\n",
    "    json.dump(texts[:], f, indent=2)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
